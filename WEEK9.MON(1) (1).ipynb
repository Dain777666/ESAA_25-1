{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d6fa114-9ed1-4091-a1ee-d7ced9dc1a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "cust_df = pd.read_csv(\"./train_santander.csv\", encoding='latin-1')\n",
    "print('dataset shape:', cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c71362-d547-4216-989f-24b19e73e967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082bafc1-2813-41f6-b430-a16c32914b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "0    73012\n",
      "1     3008\n",
      "Name: count, dtype: int64\n",
      "unsatisfied 비율은 0.04\n"
     ]
    }
   ],
   "source": [
    "print(cust_df['TARGET'].value_counts())\n",
    "unsatisfied_cnt = cust_df[cust_df['TARGET'] == 1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "print('unsatisfied 비율은 {0:.2f}'.format((unsatisfied_cnt / total_cnt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "746bbc6b-d6ee-48f4-997d-5e4d75328f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>76020.000000</td>\n",
       "      <td>7.602000e+04</td>\n",
       "      <td>76020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75964.050723</td>\n",
       "      <td>-1523.199277</td>\n",
       "      <td>33.212865</td>\n",
       "      <td>86.208265</td>\n",
       "      <td>72.363067</td>\n",
       "      <td>119.529632</td>\n",
       "      <td>3.559130</td>\n",
       "      <td>6.472698</td>\n",
       "      <td>0.412946</td>\n",
       "      <td>0.567352</td>\n",
       "      <td>...</td>\n",
       "      <td>7.935824</td>\n",
       "      <td>1.365146</td>\n",
       "      <td>12.215580</td>\n",
       "      <td>8.784074</td>\n",
       "      <td>31.505324</td>\n",
       "      <td>1.858575</td>\n",
       "      <td>76.026165</td>\n",
       "      <td>56.614351</td>\n",
       "      <td>1.172358e+05</td>\n",
       "      <td>0.039569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43781.947379</td>\n",
       "      <td>39033.462364</td>\n",
       "      <td>12.956486</td>\n",
       "      <td>1614.757313</td>\n",
       "      <td>339.315831</td>\n",
       "      <td>546.266294</td>\n",
       "      <td>93.155749</td>\n",
       "      <td>153.737066</td>\n",
       "      <td>30.604864</td>\n",
       "      <td>36.513513</td>\n",
       "      <td>...</td>\n",
       "      <td>455.887218</td>\n",
       "      <td>113.959637</td>\n",
       "      <td>783.207399</td>\n",
       "      <td>538.439211</td>\n",
       "      <td>2013.125393</td>\n",
       "      <td>147.786584</td>\n",
       "      <td>4040.337842</td>\n",
       "      <td>2852.579397</td>\n",
       "      <td>1.826646e+05</td>\n",
       "      <td>0.194945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999999.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.163750e+03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38104.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.787061e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76043.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.064092e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113748.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187563e+05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151838.000000</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>12888.030000</td>\n",
       "      <td>21024.810000</td>\n",
       "      <td>8237.820000</td>\n",
       "      <td>11073.570000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>50003.880000</td>\n",
       "      <td>20385.720000</td>\n",
       "      <td>138831.630000</td>\n",
       "      <td>91778.730000</td>\n",
       "      <td>438329.220000</td>\n",
       "      <td>24650.010000</td>\n",
       "      <td>681462.900000</td>\n",
       "      <td>397884.300000</td>\n",
       "      <td>2.203474e+07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2702d4ec-397c-439a-b0c0-c63b9cea4925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var3\n",
      " 2         74165\n",
      " 8           138\n",
      "-999999      116\n",
      " 9           110\n",
      " 3           108\n",
      " 1           105\n",
      " 13           98\n",
      " 7            97\n",
      " 4            86\n",
      " 12           85\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# var3 칼럼의 경우 min 값이 -999999\n",
    "# NaN이나 특정 예외 값을 -99999로 변환했을 것\n",
    "\n",
    "print(cust_df.var3.value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28bd16db-82ed-47f0-b5e9-b43dd19a1464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피처 데이터 shape:(76020, 369)\n"
     ]
    }
   ],
   "source": [
    "cust_df['var3'].replace(-999999, 2, inplace=True)\n",
    "cust_df.drop('ID', axis=1, inplace=True)\n",
    "\n",
    "# 피처 세트와 레이블 데이트 세트 분리. 레이블 칼럼은 DataFrame의 맨 마지막에 위치해 칼럼 위치 -1 로 분리\n",
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:, -1]\n",
    "print('피처 데이터 shape:{0}'.format(X_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deea4c8e-a6f8-4596-bf87-6159187c4941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 세트 Shape:(60816, 369), 테스트 세트 Shape:(15204, 369)\n",
      " 학습 세트 레이블 값 분포 비율\n",
      "TARGET\n",
      "0    0.960964\n",
      "1    0.039036\n",
      "Name: count, dtype: float64\n",
      "\n",
      " 테스트 세트 레이블 값 분포 비율\n",
      "TARGET\n",
      "0    0.9583\n",
      "1    0.0417\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=0)\n",
    "\n",
    "train_cnt = y_train.count()\n",
    "test_cnt = y_test.count()\n",
    "print('학습 세트 Shape:{0}, 테스트 세트 Shape:{1}'.format(X_train.shape, X_test.shape))\n",
    "\n",
    "print(' 학습 세트 레이블 값 분포 비율')\n",
    "print(y_train.value_counts()/train_cnt)\n",
    "print('\\n 테스트 세트 레이블 값 분포 비율')\n",
    "print(y_test.value_counts()/test_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44256378-c94f-4786-8160-3819d0f5cbb2",
   "metadata": {},
   "source": [
    "- 학습과 테스트 데이터 세트 모두 TARGET의 값의 분포가 원본 데이터와 유사하게 전체 데이터의 4% 정도의 불만족 값(값 1)으로 만들어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b823c3-5a73-419a-9d1b-76a0195faa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train을 다시 학습과 검증 데이터 세트로 분리\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed95e27c-9b3b-4af8-82a5-9d54b277d4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8415\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# n_estimators는 500으로, random state는 매개 수행 시마다 동일 예측 결과를 위해 설정\n",
    "# early_stopping_rounds와 eval_metric 파라미터를 XGBClassifier 초기화 시 설정\n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=0.05, random_state=156,\n",
    "                        early_stopping_rounds=100,  eval_metric=\"auc\")\n",
    "\n",
    "# eval_set은 유지\n",
    "# verbose=True를 넣어 로그 확인 가능\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)], verbose=False) \n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69a6845d-90b2-43a4-abb2-22b4d2458248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 15까지 1 간격으로, min_child_weight는 1에서 6까지 1 간격으로\n",
    "# colsample_bytree는 0.5에서 0.95 사이, learning_rate는 0.01 에서 0.2 사이 정규 분포된 값으로 검색\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 15, 1),\n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 0.95),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095ff382-536c-47ca-86cd-2d9a767a80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# fmin()에서 호출 시 search_space 값으로 XGBClassifier 교차 검증 학습 후 -1* roc_auc 평균 값을 반환\n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            early_stopping_rounds=30, eval_metric=\"auc\")\n",
    "    \n",
    "    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
    "    roc_auc_list = []\n",
    "\n",
    "    # 3개 k-fold 방식 적용\n",
    "    kf = KFold(n_splits=3)\n",
    "    # X_train을 다시 학습과 검증용 데이터로 분리\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        # kf.split(X_train)으로 추출된 학습과 검증 index 값으로 학습과 검증 데이터 세트 분리\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행\n",
    "        xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "        # 1로 예측한 확률값 추출 후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결괏값 담음\n",
    "        score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:, 1 ]) \n",
    "        roc_auc_list.append(score)\n",
    "\n",
    "    # 3개 k-fold로 계산된 roc.auc 값의 평균값을 반환하되,\n",
    "    # HyperOpt는 목적함수의 최솟값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환\n",
    "    return -1*np.mean(roc_auc_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d341b4e-137e-46dd-a2e1-cf2313dca694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# fmin() 함수를 호출. max_evals 지정된 횟수만큼 반복 후 목적함수의 최솟값을 가지는 최적 입력값 추출\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials, rstate=np.random.default_rng(seed=30),\n",
    "            verbose=False)\n",
    "\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da602d-7c9b-4be7-9e55-b5b0f7620541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators를 500 증가 후 최적으로 찾은 하이퍼 파라미터를 기반으로 학습과 예측 수행\n",
    "xgb_clf = XGBClassifier(n_estimators=500, learning_rate=round(best['learning_rate'], 5), \n",
    "                        max_depth=int(best['max_depth']), \n",
    "                        min_child_weight=int(best['min_child_weight']), \n",
    "                        colsample_bytree=round(best['colsample_bytree'], 5),\n",
    "                        early_stopping_rounds=100,\n",
    "                        eval_metric=\"auc\",)\n",
    "\n",
    "# evaluation metric을 auc로, early stopping은 100으로 설정하고 학습 수행\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)], verbose=False)\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC： {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74493b04-dccc-4f2a-82e3-bf45ea45b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,8))\n",
    "plot_importance(xgb_clf, ax=ax , max_num_features=20, height=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26f2c13f-71b8-40d6-afc5-3e89001c92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 위의 세 코드는 실행이 오래 걸려서 중간에 중단시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a96a1e6-3e7c-45f3-8b00-b8f14bbcde3d",
   "metadata": {},
   "source": [
    "- ROC—AUC가 이전 예제의 0.8415에서 하이퍼 파라미터 튜닝 이후 0.8444로 개선되었음. 물론 시간을 투자한 것만큼은 아닐 수 있으나 캐글과 같이 치열한 순위 경쟁이 필요한 경우에는 이 정도의 수치 개선은 도움이 될 수 있음.\n",
    "  \n",
    "- 한 가지 아쉬운 점은 XGBoost가 GBM보다는 빠르지만 아무래도 GBM을 기반으로 하고 있기 때문에 수행 시간이 상당히 더 많이 요구된다는 점임. 앙상블 계열 알고리즘에서 하이퍼 파라미터 튜닝으로 성능 수치 개선이 급격하게 되는 경우는 많지 않음. 앙상블 계열 알고리즘은 과적합이나 잡음에 기본적으로 뛰어난 알고리즘이기 때문임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3be540-780a-4a60-bf15-52f68df85b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LightGBM 모델 학습과 하이퍼 파라미터 튜닝 ##\n",
    "\n",
    "# 앞의 XGBoost 예제와 동일하게 n_estimators는 500으로 설정하고, \n",
    "# early_stopping_rounds는 100, \n",
    "# 앞에서 분리한 학습과 검증 데이터 세트를 이용하여 eval_set=[(X_tr, y_tr),(X_val, y_val)]으로 \n",
    "# 학습을 진행한 뒤 테스트 데이터 세트로 평가된 ROC-AUC 값을 확인해봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e7cfa0-7967-4341-9e13-2ca639f6c2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1658, number of negative: 40913\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13308\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 242\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038947 -> initscore=-3.205836\n",
      "[LightGBM] [Info] Start training from score -3.205836\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.112183\tvalid_1's binary_logloss: 0.13527\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "ROC AUC： 0.8384\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators=500, early_stopping_rounds=100, eval_metric=\"auc\",)\n",
    "\n",
    "eval_set=[(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_set=eval_set)\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:,1])\n",
    "print('ROC AUC： {0:.4f}'.format(lgbm_roc_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0fb873-57e6-45a5-8e0c-2ec6611673ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search_space = {'num_leaves': hp.quniform('num_leaves', 32, 64, 1),\n",
    "                     'max_depth': hp.quniform('max_depth', 100, 160, 1 ),\n",
    "                     'min_child_samples' : hp.quniform('min_child_samples', 60, 100, 1), \n",
    "                     'subsample': hp.uniform('subsample', 0.7, 1),\n",
    "                     'learning_rate': hp.uniform('learning_rate', 0.01, 0.2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "551d84e6-149d-4ebd-afd5-d7d268157d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    lgbm_clf = LGBMClassifier(n_estimators=100, \n",
    "                            num_leaves=int(search_space['num_leaves']),\n",
    "                            max_depth=int(search_space['max_depth']),\n",
    "                            min_child_samples=int(search_space['min_child_samples']),\n",
    "                            subsample=search_space['subsample'],\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            early_stopping_rounds=30, \n",
    "                            eval_metric=\"auc\")\n",
    "    \n",
    "    # 3개 k-fold 방식으로 평가된 roc_auc 지표를 담는 list\n",
    "    roc_auc_list = []\n",
    "\n",
    "    # 3개 k-fold 방식 적용\n",
    "    kf = KFold(n_splits=3)\n",
    "    # X_train을 다시 학습과 검증용 데이터로 분리\n",
    "    for tr_index, val_index in kf.split(X_train):\n",
    "        # kf.split(X_train)으로 추출된 학습과 검증 index 값으로 학습과 검증 데이터 세트 분리\n",
    "        X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
    "        X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        # early stopping은 30회로 설정하고 추출된 학습과 검증 데이터로 XGBClassifier 학습 수행\n",
    "        lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "        # 1로 예측한 확률값 추출 후 roc auc 계산하고 평균 roc auc 계산을 위해 list에 결괏값 담음\n",
    "        score = roc_auc_score(y_val, lgbm_clf.predict_proba(X_val)[:, 1]) \n",
    "        roc_auc_list.append(score)\n",
    "\n",
    "    # 3개 k-fold로 계산된 roc.auc 값의 평균값을 반환하되,\n",
    "    # HyperOpt는 목적함수의 최솟값을 위한 입력값을 찾으므로 -1을 곱한 뒤 반환\n",
    "    return -1*np.mean(roc_auc_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a3c8cf7-dc09-4c6c-b2a7-b565f2c8195e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.121691\tvalid_1's binary_logloss: 0.135854\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.123806\tvalid_1's binary_logloss: 0.13102\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.121345\tvalid_1's binary_logloss: 0.136434\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.116101\tvalid_1's binary_logloss: 0.13651\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.115144\tvalid_1's binary_logloss: 0.131217\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055668 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.114807\tvalid_1's binary_logloss: 0.137799\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.117842\tvalid_1's binary_logloss: 0.13612\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.116124\tvalid_1's binary_logloss: 0.130594\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.115344\tvalid_1's binary_logloss: 0.136679\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12895\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.110829\tvalid_1's binary_logloss: 0.136072\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.108961\tvalid_1's binary_logloss: 0.130846\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047817 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's binary_logloss: 0.110318\tvalid_1's binary_logloss: 0.137738\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.115347\tvalid_1's binary_logloss: 0.135605\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.115128\tvalid_1's binary_logloss: 0.130766\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.114029\tvalid_1's binary_logloss: 0.136655\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.127637\tvalid_1's binary_logloss: 0.137831\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.129898\tvalid_1's binary_logloss: 0.133066\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042122 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.127136\tvalid_1's binary_logloss: 0.138892\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.120387\tvalid_1's binary_logloss: 0.136333\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.118736\tvalid_1's binary_logloss: 0.131262\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045395 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's binary_logloss: 0.116468\tvalid_1's binary_logloss: 0.137155\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.115785\tvalid_1's binary_logloss: 0.136488\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.114888\tvalid_1's binary_logloss: 0.131395\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.113891\tvalid_1's binary_logloss: 0.138015\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.119098\tvalid_1's binary_logloss: 0.136082\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.118696\tvalid_1's binary_logloss: 0.131068\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.116749\tvalid_1's binary_logloss: 0.136189\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.117245\tvalid_1's binary_logloss: 0.136033\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.115521\tvalid_1's binary_logloss: 0.130554\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.116854\tvalid_1's binary_logloss: 0.136736\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.114779\tvalid_1's binary_logloss: 0.136755\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13094\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.115313\tvalid_1's binary_logloss: 0.133237\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.112274\tvalid_1's binary_logloss: 0.139062\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.114367\tvalid_1's binary_logloss: 0.136203\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.113074\tvalid_1's binary_logloss: 0.131037\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.111096\tvalid_1's binary_logloss: 0.137228\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12922\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.11902\tvalid_1's binary_logloss: 0.136321\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13050\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's binary_logloss: 0.11568\tvalid_1's binary_logloss: 0.131373\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.113956\tvalid_1's binary_logloss: 0.137568\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12895\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.113833\tvalid_1's binary_logloss: 0.13584\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.113411\tvalid_1's binary_logloss: 0.130684\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.11079\tvalid_1's binary_logloss: 0.13635\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.119835\tvalid_1's binary_logloss: 0.135834\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.117984\tvalid_1's binary_logloss: 0.131018\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.114383\tvalid_1's binary_logloss: 0.136812\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.114433\tvalid_1's binary_logloss: 0.135977\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.112461\tvalid_1's binary_logloss: 0.131242\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.111934\tvalid_1's binary_logloss: 0.137242\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045280 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12835\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.120091\tvalid_1's binary_logloss: 0.135824\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.12218\tvalid_1's binary_logloss: 0.13083\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12863\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.119522\tvalid_1's binary_logloss: 0.136618\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034418 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.116893\tvalid_1's binary_logloss: 0.136357\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.113216\tvalid_1's binary_logloss: 0.13115\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.110917\tvalid_1's binary_logloss: 0.136891\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12885\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.114527\tvalid_1's binary_logloss: 0.136277\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.113994\tvalid_1's binary_logloss: 0.131827\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.113791\tvalid_1's binary_logloss: 0.137537\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.119715\tvalid_1's binary_logloss: 0.135597\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.121795\tvalid_1's binary_logloss: 0.130833\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.119143\tvalid_1's binary_logloss: 0.136485\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.115666\tvalid_1's binary_logloss: 0.135727\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049894 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's binary_logloss: 0.118088\tvalid_1's binary_logloss: 0.130656\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's binary_logloss: 0.115823\tvalid_1's binary_logloss: 0.136543\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12926\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 203\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.115388\tvalid_1's binary_logloss: 0.135942\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 13094\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 205\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.115476\tvalid_1's binary_logloss: 0.130922\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12950\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.113368\tvalid_1's binary_logloss: 0.13644\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.128787\tvalid_1's binary_logloss: 0.137803\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12954\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.131041\tvalid_1's binary_logloss: 0.133108\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.128267\tvalid_1's binary_logloss: 0.138809\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.117721\tvalid_1's binary_logloss: 0.135749\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.1202\tvalid_1's binary_logloss: 0.130426\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.117598\tvalid_1's binary_logloss: 0.135991\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.118799\tvalid_1's binary_logloss: 0.135841\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.116214\tvalid_1's binary_logloss: 0.13057\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047686 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.118269\tvalid_1's binary_logloss: 0.136548\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.120175\tvalid_1's binary_logloss: 0.135615\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.119917\tvalid_1's binary_logloss: 0.130481\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.049334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\ttraining's binary_logloss: 0.117594\tvalid_1's binary_logloss: 0.135984\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.132023\tvalid_1's binary_logloss: 0.140025\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.134325\tvalid_1's binary_logloss: 0.135128\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.131493\tvalid_1's binary_logloss: 0.141144\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.115089\tvalid_1's binary_logloss: 0.135956\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.115673\tvalid_1's binary_logloss: 0.130635\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.115611\tvalid_1's binary_logloss: 0.13686\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.115813\tvalid_1's binary_logloss: 0.135322\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.117963\tvalid_1's binary_logloss: 0.130349\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050743 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.114921\tvalid_1's binary_logloss: 0.136087\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[86]\ttraining's binary_logloss: 0.116619\tvalid_1's binary_logloss: 0.135645\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.117938\tvalid_1's binary_logloss: 0.130448\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[77]\ttraining's binary_logloss: 0.117748\tvalid_1's binary_logloss: 0.136235\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.11633\tvalid_1's binary_logloss: 0.135504\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.120421\tvalid_1's binary_logloss: 0.130419\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.115794\tvalid_1's binary_logloss: 0.135859\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052430 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.116404\tvalid_1's binary_logloss: 0.135806\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.118006\tvalid_1's binary_logloss: 0.13048\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.114515\tvalid_1's binary_logloss: 0.13597\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.117342\tvalid_1's binary_logloss: 0.135969\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.113141\tvalid_1's binary_logloss: 0.131089\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.115371\tvalid_1's binary_logloss: 0.136859\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050946 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.114195\tvalid_1's binary_logloss: 0.136286\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.109021\tvalid_1's binary_logloss: 0.131129\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.113768\tvalid_1's binary_logloss: 0.137725\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.120097\tvalid_1's binary_logloss: 0.135686\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's binary_logloss: 0.119396\tvalid_1's binary_logloss: 0.130514\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's binary_logloss: 0.116378\tvalid_1's binary_logloss: 0.1362\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.11705\tvalid_1's binary_logloss: 0.1355\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.117347\tvalid_1's binary_logloss: 0.130237\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.115092\tvalid_1's binary_logloss: 0.136329\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's binary_logloss: 0.114995\tvalid_1's binary_logloss: 0.136039\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.11569\tvalid_1's binary_logloss: 0.13063\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.113835\tvalid_1's binary_logloss: 0.13665\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.11721\tvalid_1's binary_logloss: 0.135984\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.058117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.114459\tvalid_1's binary_logloss: 0.130701\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041904 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.115871\tvalid_1's binary_logloss: 0.136668\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.120348\tvalid_1's binary_logloss: 0.136155\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.119451\tvalid_1's binary_logloss: 0.131012\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.11645\tvalid_1's binary_logloss: 0.136451\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.12009\tvalid_1's binary_logloss: 0.135675\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.118193\tvalid_1's binary_logloss: 0.130602\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.11623\tvalid_1's binary_logloss: 0.136153\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's binary_logloss: 0.116738\tvalid_1's binary_logloss: 0.135853\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's binary_logloss: 0.117418\tvalid_1's binary_logloss: 0.130448\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.113352\tvalid_1's binary_logloss: 0.136288\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.116344\tvalid_1's binary_logloss: 0.136167\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045139 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.113436\tvalid_1's binary_logloss: 0.131078\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.113935\tvalid_1's binary_logloss: 0.137141\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.112933\tvalid_1's binary_logloss: 0.136188\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056101 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.115172\tvalid_1's binary_logloss: 0.130748\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.114785\tvalid_1's binary_logloss: 0.136832\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049781 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.117312\tvalid_1's binary_logloss: 0.135902\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043732 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.118173\tvalid_1's binary_logloss: 0.131307\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.115554\tvalid_1's binary_logloss: 0.137295\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054923 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.121907\tvalid_1's binary_logloss: 0.135965\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12954\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 195\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.124035\tvalid_1's binary_logloss: 0.131212\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.121394\tvalid_1's binary_logloss: 0.136876\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12895\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 199\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.11663\tvalid_1's binary_logloss: 0.136189\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13046\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 202\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.117802\tvalid_1's binary_logloss: 0.131163\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12915\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.109973\tvalid_1's binary_logloss: 0.13719\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.119207\tvalid_1's binary_logloss: 0.135473\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.119242\tvalid_1's binary_logloss: 0.130134\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.116569\tvalid_1's binary_logloss: 0.136171\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.114617\tvalid_1's binary_logloss: 0.136351\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 13008\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 197\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.112433\tvalid_1's binary_logloss: 0.131448\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.112794\tvalid_1's binary_logloss: 0.137877\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.114476\tvalid_1's binary_logloss: 0.137269\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's binary_logloss: 0.117329\tvalid_1's binary_logloss: 0.132223\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.118661\tvalid_1's binary_logloss: 0.138344\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1579, number of negative: 38965\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12827\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038945 -> initscore=-3.205872\n",
      "[LightGBM] [Info] Start training from score -3.205872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.124109\tvalid_1's binary_logloss: 0.136673\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1609, number of negative: 38935\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12946\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039685 -> initscore=-3.186281\n",
      "[LightGBM] [Info] Start training from score -3.186281\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.126412\tvalid_1's binary_logloss: 0.131761\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1560, number of negative: 38984\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12855\n",
      "[LightGBM] [Info] Number of data points in the train set: 40544, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=30, early_stopping_rounds=30 will be ignored. Current value: early_stopping_round=30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038477 -> initscore=-3.218465\n",
      "[LightGBM] [Info] Start training from score -3.218465\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's binary_logloss: 0.123614\tvalid_1's binary_logloss: 0.137451\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "best: {'learning_rate': 0.07283348800335702, 'max_depth': 133.0, 'min_child_samples': 89.0, 'num_leaves': 32.0, 'subsample': 0.7011491391896255}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials \n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# fmin() 함수를 호출. max_evals 지정된 횟수만큼 반복 후 목적함수의 최솟값을 가지는 최적 입력값 추출\n",
    "best = fmin(fn=objective_func, space=lgbm_search_space, algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials, \n",
    "            rstate=np.random.default_rng(seed=30),\n",
    "            verbose=False)\n",
    "\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f0f9e87-ab53-4f6c-95bb-bebe9be45fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Info] Number of positive: 1658, number of negative: 40913\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12898\n",
      "[LightGBM] [Info] Number of data points in the train set: 42571, number of used features: 192\n",
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n",
      "[LightGBM] [Warning] early_stopping_round is set=100, early_stopping_rounds=100 will be ignored. Current value: early_stopping_round=100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038947 -> initscore=-3.205836\n",
      "[LightGBM] [Info] Start training from score -3.205836\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.118292\tvalid_1's binary_logloss: 0.134797\n",
      "ROC AUC: 0.8415\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=500, num_leaves=int(best['num_leaves']), \n",
    "                        max_depth=int(best['max_depth']), \n",
    "                        min_child_samples=int(best['min_child_samples']), \n",
    "                        subsample=round(best['subsample'], 5), \n",
    "                        learning_rate=round(best['learning_rate'], 5),\n",
    "                        early_stopping_rounds=100, \n",
    "                        eval_metric=\"auc\")\n",
    "\n",
    "# evaluation metric을 auc로, early stopping은 100으로 설정하고 학습 수행\n",
    "lgbm_clf.fit(X_tr, y_tr, eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1]) \n",
    "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
